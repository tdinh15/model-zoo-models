{
  "models": [
    {
      "id": "audio-recognition",
      "full_name": "Audio Recognition",
      "description": "A recurrent neural network for performing speech recognition.",
      "model_type": "Audio Recognition",
      "repository_url": "https://github.com/latentai/model-zoo-models/tree/master/audio_recognition",
      "variants": [
        {
          "id": "tf-baseline",
          "show_in_frontend": true,
          "metrics_json": null,
          "weights_url": "https://model-zoo-data.latentai.io/model-weights/audio-recognition/tf-baseline/2020-05-08-22-19-58/a62d0f14960f4b1db27ad1cd3fe9d5f0.zip",
          "model_schema": {
            "output_names": "Add_2",
            "input_names": "fingerprint_input",
            "preprocessor": "speechcommand",
            "task": "classifier",
            "dataset": "custom",
            "input_shapes": "1,3920"
          }
        }
      ]
    },
    {
      "id": "lenet_gtc",
      "full_name": "LeNet (Training Aware)",
      "description": "The classic LeNet convolutional neural network proposed by Yann LeCun, trained using Training Aware quantization.",
      "model_type": "Image Classification",
      "repository_url": "https://github.com/latentai/model-zoo-models/tree/master/lenet_gtc",
      "variants": [
        {
          "id": "high_precision",
          "show_in_frontend": false,
          "metrics_json": "lenet_gtc/metrics/mnist_high_precision.json",
          "weights_url": "https://model-zoo-data.latentai.io/lenet_gtc/high_precision/2020-05-28-02-17-21/8a7a3b9d6367df74898802fc02c08f43.zip",
          "training_dataset": {
            "dataset_id": "mnist",
            "variant_id": "train"
          },
          "model_schema": {
            "dataset": "custom",
            "input_names": "Placeholder",
            "input_shapes": "1,28,28,1",
            "output_names": "Softmax",
            "preprocessor": "rgbtogray",
            "task": "classifier"
          }
        },
        {
          "id": "low_precision",
          "show_in_frontend": true,
          "metrics_json": "lenet_gtc/metrics/mnist_low_precision.json",
          "weights_url": "https://model-zoo-data.latentai.io/lenet_gtc/low_precision/2020-05-28-02-22-39/09d07d11f1f7784e983470ac8b49727d.zip",
          "training_dataset": {
            "dataset_id": "mnist",
            "variant_id": "train"
          },
          "model_schema": {
            "dataset": "custom",
            "input_names": "Placeholder",
            "input_shapes": "1,28,28,1",
            "output_names": "Softmax",
            "preprocessor": "rgbtogray",
            "task": "classifier"
          }
        }
      ]
    },
    {
      "id": "yolo",
      "full_name": "YOLOv3",
      "description": "YOLO (You Only Look Once), is a deep neural network architecture for object detection. YOLO differentiates itself from other common neural network architectures for object detection tasks in that it performs inference using a single forward pass through a single neural network.",
      "model_type": "Object Recognition",
      "repository_url": "https://github.com/latentai/model-zoo-models/tree/master/yolo",
      "variants": [
        {
          "id": "keras-pretrained",
          "show_in_frontend": false,
          "metrics_json": "yolo/metrics/pascal-voc2007.json",
          "training_dataset": {
            "dataset_id": "pascal-voc2007",
            "variant_id": "full-dataset"
          },
          "weights_url": "https://model-zoo-data.latentai.io/model-weights/yolo/keras-pretrained/2020-05-01-22-06-25/dbb0dbdd8a08b93023053fb553d6ba70.zip",
          "model_schema": {
            "output_names": "conv_81/BiasAdd,conv_93/BiasAdd,conv_105/BiasAdd",
            "input_names": "input_1",
            "input_shapes": "1, 416, 416, 3",
            "preprocessor": "float32"
          }
        },
        {
          "id": "keras-pretrained-backbone",
          "show_in_frontend": false,
          "metrics_json": null,
          "weights_url": "http://model-zoo-data.latentai.io.s3.amazonaws.com/model-weights/yolo/2020-04-21-12-12-17/62186a8066b28c8af75bdcf3be019cda.zip",
          "model_schema": {}
        }
      ]
    },
    {
      "id": "mobilenetv1",
      "full_name": "Mobilenet V1",
      "description": "Mobilenet V1 is an image classification model that implements depth-wise convolutions within the network in an effort to reduce latency on mobile devices.",
      "model_type": "Image Classification",
      "repository_url": "https://github.com/latentai/model-zoo-models/tree/master/mobilenetv1",
      "variants": [
        {
          "id": "keras-open-images-10-classes",
          "show_in_frontend": true,
          "weights_url": "https://model-zoo-data.latentai.io/mobilenetv1/keras-open-images-10-classes/2020-05-10-06-04-12/ad71dcba22296da33dbe75b379c84016.zip",
          "training_dataset": {
            "dataset_id": "open-images-10-classes",
            "variant_id": "train"
          },
          "metrics_json": "mobilenetv1/metrics/open_images.json",
          "model_schema": {
            "output_names": "dense_3/Softmax",
            "input_names": "input_1",
            "preprocessor": "imagenet",
            "input_shapes": "1,224,224,3",
            "task": "classifier",
            "dataset": "custom"
          }
        },
        {
          "id": "keras-imagenet",
          "show_in_frontend": true,
          "weights_url": "https://model-zoo-data.latentai.io/mobilenetv1/keras-imagenet/2020-04-13-23-38-12/ad27ad2f39b3d73215ae55839d72eeca.zip",
          "training_dataset": {
            "dataset_id": "imagenet",
            "variant_id": "train"
          },
          "metrics_json": null,
          "model_schema": {
            "output_names": "act_softmax/Softmax",
            "input_names": "input_1",
            "preprocessor": "imagenet",
            "input_shapes": "1,224,224,3",
            "task": "classifier",
            "dataset": "custom"
          }
        }
      ]
    },
    {
      "id": "mobilenetv2",
      "full_name": "Mobilenet V2",
      "description": "Mobilenet V2 is an image classification model that implements depth-wise convolutions within the network in an effort to optimize latency on mobile devices. MobilenetV2 is architecturally similar to V1, but has been further optimized to reduce latency on mobile devices.",
      "model_type": "Image Classification",
      "repository_url": "https://github.com/latentai/model-zoo-models/tree/master/mobilenetv2",
      "variants": [
        {
          "id": "keras-open-images-10-classes",
          "show_in_frontend": true,
          "weights_url": "https://model-zoo-data.latentai.io/mobilenetv2/keras-open-images-10-classes/2020-05-10-06-04-22/18c74b63eb661685610964b681c39682.zip",
          "training_dataset": {
            "dataset_id": "open-images-10-classes",
            "variant_id": "train"
          },
          "metrics_json": "mobilenetv2/metrics/open_images.json",
          "model_schema": {
            "output_names": "dense_3/Softmax",
            "input_names": "input_1",
            "preprocessor": "imagenet",
            "input_shapes": "1,224,224,3",
            "task": "classifier",
            "dataset": "custom"
          }
        },
        {
          "id": "keras-imagenet",
          "show_in_frontend": true,
          "weights_url": "https://model-zoo-data.latentai.io/mobilenetv2/keras-imagenet/2020-04-13-23-38-21/7b91c2ab8d28181894ce3a423cb8eb1c.zip",
          "training_dataset": {
            "dataset_id": "imagenet",
            "variant_id": "train"
          },
          "metrics_json": "mobilenetv2/metrics/imagenet.json",
          "model_schema": {
            "output_names": "Logits/Softmax",
            "input_names": "input_1",
            "preprocessor": "imagenet",
            "input_shapes": "1,224,224,3",
            "task": "classifier",
            "dataset": "custom"
          }
        }
      ]
    },
    {
      "id": "resnetv2-50",
      "full_name": "Resnetv2-50",
      "description": "Resnetv2-50 is a convolutional neural network used for image classification that is 50 layers deep. ResNet is a residual neural network known for it's ability to learn skip functions during training, allowing it to effectively skip layers during the training process resulting in a simplflied neural network that uses fewer layers.",
      "model_type": "Image Classification",
      "repository_url": "https://github.com/latentai/model-zoo-models/tree/master/resnet50",
      "variants": [
        {
          "id": "keras-open-images-10-classes",
          "show_in_frontend": true,
          "weights_url": "https://model-zoo-data.latentai.io/resnetv2-50/keras-open-images-10-classes/2020-05-01-22-45-06/f1df15768ffe7119fef675425871f7e8.zip",
          "training_dataset": {
            "dataset_id": "open-images-10-classes",
            "variant_id": "train"
          },
          "metrics_json": "resnet50/metrics/open_images.json",
          "model_schema": {
            "output_names": "dense/Softmax",
            "input_names": "input_1",
            "preprocessor": "imagenet_caffe",
            "input_shapes": "1,224,224,3",
            "task": "classifier",
            "dataset": "custom"
          }
        },
        {
          "id": "keras-imagenet",
          "show_in_frontend": true,
          "weights_url": "https://model-zoo-data.latentai.io/resnetv2-50/keras-imagenet/2020-04-13-23-38-32/69598b3630011f49cbb582704cbeefac.zip",
          "training_dataset": {
            "dataset_id": "imagenet",
            "variant_id": "train"
          },
          "metrics_json": "resnet50/metrics/imagenet.json",
          "model_schema": {
            "output_names": "probs/Softmax",
            "input_names": "input_1",
            "preprocessor": "imagenet_caffe",
            "input_shapes": "1,224,224,3",
            "task": "classifier",
            "dataset": "custom"
          }
        }
      ]
    },
    {
      "id": "vgg16",
      "full_name": "VGG16",
      "description": "VGG16 is a convolution neural network with 16 layers that acheives high performance on image classifcation tasks.",
      "model_type": "Image Classification",
      "repository_url": "https://github.com/latentai/model-zoo-models/tree/master/vgg16",
      "variants": [
        {
          "id": "keras-open-images-10-classes",
          "show_in_frontend": true,
          "weights_url": "https://model-zoo-data.latentai.io/vgg16/keras-open-images-10-classes/2020-05-10-06-04-03/9ee32f34625d59260d4c102048562c70.zip",
          "training_dataset": {
            "dataset_id": "open-images-10-classes",
            "variant_id": "train"
          },
          "metrics_json": "vgg16/metrics/open_images.json",
          "model_schema": {
            "output_names": "dense/Softmax",
            "input_names": "input_1",
            "preprocessor": "imagenet_caffe",
            "input_shapes": "1,224,224,3",
            "task": "classifier",
            "dataset": "custom"
          }
        },
        {
          "id": "keras-imagenet",
          "show_in_frontend": true,
          "weights_url": "https://model-zoo-data.latentai.io/vgg16/keras-imagenet/2020-04-13-23-39-07/90cd0632afb0fa49925398d9f6ea9880.zip",
          "training_dataset": {
            "dataset_id": "imagenet",
            "variant_id": "train"
          },
          "metrics_json": "vgg16/metrics/imagenet.json",
          "model_schema": {
            "output_names": "predictions/Softmax",
            "input_names": "input_1",
            "preprocessor": "imagenet_caffe",
            "input_shapes": "1,224,224,3",
            "task": "classifier",
            "dataset": "custom"
          }
        }
      ]
    },
    {
      "id": "inceptionv3",
      "full_name": "Inception V3",
      "description": "Inception V3 is a convolutional neural network developed by Google to perform image classificaiton tasks.",
      "model_type": "Image Classification",
      "repository_url": "https://github.com/latentai/model-zoo-models/tree/master/inceptionv3",
      "variants": [
        {
          "id": "keras-open-images-10-classes",
          "show_in_frontend": true,
          "weights_url": "https://model-zoo-data.latentai.io/inceptionv3/keras-open-images-10-classes/2020-05-10-06-03-51/2ec10b01b84245df120ae24d00b1b4b0.zip",
          "training_dataset": {
            "dataset_id": "open-images-10-classes",
            "variant_id": "train"
          },
          "metrics_json": "inceptionv3/metrics/open_images.json",
          "model_schema": {
            "output_names": "dense/Softmax",
            "input_names": "input_1",
            "preprocessor": "imagenet",
            "input_shapes": "1,224,224,3",
            "task": "classifier",
            "dataset": "custom"
          }
        },
        {
          "id": "keras-imagenet",
          "show_in_frontend": true,
          "weights_url": "https://model-zoo-data.latentai.io/inceptionv3/keras-imagenet/2020-04-13-23-37-59/321a4048251230bca334403319ab9d71.zip",
          "training_dataset": {
            "dataset_id": "imagenet",
            "variant_id": "train"
          },
          "metrics_json": "inceptionv3/metrics/imagenet.json",
          "model_schema": {
            "output_names": "predictions/Softmax",
            "input_names": "input_1",
            "preprocessor": "imagenet",
            "input_shapes": "1,224,224,3",
            "task": "classifier",
            "dataset": "custom"
          }
        }
      ]
    }
  ],
  "datasets": [
    {
      "id": "open-images-10-classes",
      "full_name": "Open Images 10-Classes",
      "description": "A 10-class object recognition dataset compiled from the larger Google Open Images V5 dataset. Each class contains an average of 163 images with labels.",
      "variants": [
        {
          "id": "train",
          "data_url": "https://model-zoo-data.latentai.io/datasets/open-images-10-classes/train/2020-05-01-19-15-57/c8499f9a0606cb5dc225bf7578b51279.zip"
        },
        {
          "id": "eval",
          "data_url": "https://model-zoo-data.latentai.io/datasets/open-images-10-classes/eval/2020-05-01-19-11-29/360a64f2fa62ae5ab8913186c8623ca7.zip"
        }
      ]
    },
    {
      "id": "pascal-voc2007",
      "full_name": "Pascal VOC 2007",
      "description": "The goal of this challenge is to recognize objects from 20 visual object classes in realistic scenes (i.e. not pre-segmented objects).",
      "variants": [
        {
          "id": "full-dataset",
          "data_url": "https://model-zoo-data.latentai.io/datasets/pascal-voc2007/full-dataset/2020-03-27-02-55-46/53e36a01c2ff00c1dad58b99f291123c.zip"
        },
        {
          "id": "train",
          "data_url": "https://model-zoo-data.latentai.io/datasets/pascal-voc2007/train/2020-05-28-23-41-32/231d115d514fda67dbfbf4a7027847c7.zip"
        },
        {
          "id": "eval",
          "data_url": "https://model-zoo-data.latentai.io/datasets/pascal-voc2007/eval/2020-05-28-23-42-07/ab613c96897d07d1cb11d22daec42338.zip"
        }
      ]
    },
    {
      "id": "google-speech-commands",
      "full_name": "Google Speech Commands",
      "variants": [
        {
          "id": "v0.02",
          "data_url": "https://model-zoo-data.latentai.io/datasets/google-speech-commands/v0.02/2020-04-30-23-19-34/0d5603d8360cab2cb56626a7837f3a05.zip"
        },
        {
          "id": "eval",
          "data_url": "https://model-zoo-data.latentai.io/datasets/google-speech-commands/eval/2020-05-07-20-19-26/61f283ce9f64b21d64161e8aa8b682f1.zip"
        },
        {
          "id": "train",
          "data_url": "https://model-zoo-data.latentai.io/datasets/google-speech-commands/train/2020-05-06-23-02-09/4e016ecc42982a6b76f973a4ef6d9c3d.zip"
        }
      ]
    },
    {
      "id": "imagenet",
      "full_name": "Imagenet",
      "variants": [
        {
          "id": "train",
          "data_url": null
        }
      ]
    },
    {
      "id": "mnist",
      "full_name": "MNIST",
      "variants": [
        {
          "id": "train",
          "data_url": null
        },
        {
          "id": "eval",
          "data_url": "https://model-zoo-data.latentai.io/datasets/mnist/eval/2020-05-28-02-50-02/ee741a0180cbb338ad24c8338cdfb752.zip"
        }
      ]
    }
  ]
}
